<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Civilization. AI. Book reviews. Startups. Effective altruism. Progress studies. Radical futures. The abolition of death.">
    <link rel="icon" type="image/svg+xml" href="assets/favicon.svg">
    <title>Bilal Chughtai </title>
    
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    
<header>
    <nav>
        <div class="site-name heading-font">Bilal Chughtai &mdash; home page</div>
    </nav>
</header>

    <div class="container">
        <div class="column left">
            <div class="sticky-div">
                

<p class="toc-heading">On this page:</p>
<nav id="toc" class="table-of-contents">
    <hr class="toc-separator">
    <ul>
        
        <li class="toc-h2">
            <a href="#section-0">About</a>
        </li>
        
        <li class="toc-h2">
            <a href="#section-1">Posts</a>
        </li>
        
    </ul>
    <hr class="toc-separator">
</nav>


            </div>
        </div>
        <div class="column main">
            <div class="collapsed-sidebar">
                
            </div>
            <div class="content">
                
<h1 class="post-title">Bilal Chughtai</h1>


<div class="collapsed-sidebar">
    <p class="toc-heading">On this page:</p>
    <nav id="collapsed-toc" class="table-of-contents">
        <hr class="toc-separator">
        <ul>
            
            <li class="toc-h2">
                <a href="#section-0">About</a>
            </li>
            
            <li class="toc-h2">
                <a href="#section-1">Posts</a>
            </li>
            
        </ul>
        <hr class="toc-separator">
    </nav>
</div>


<h2 id="section-0">About</h2>

<p>I care about and spend most of my time thinking about how to make powerful AI go well for humanity. I'll be starting on the Google DeepMind language model interpretability team in February 2024.</p>

<p>This site serves as a minimal home for the artefacts I produce on the internet.</p>

<p>
<a href="https://scholar.google.com/citations?user=i-L98bwAAAAJ&hl=en">google scholar</a> // 
<a href="https://www.linkedin.com/in/bilalchughtai/">linkedin</a> //
<a href="https://x.com/bilalchughtai_">twitter</a> // 
<a href="https://www.lesswrong.com/users/bilalchughtai">lesswrong</a> // 
<a href="https://www.instapaper.com/p/bilalchughtai">instapaper</a> // 
<a href="mailto:brchughtaii@gmail.com">email</a>
</p>



<h2 id="section-1">Posts</h2>
<div class="tab-container">
    <input type="radio" id="tab1" name="tabs" checked>
    <input type="radio" id="tab2" name="tabs">
    <input type="radio" id="tab3" name="tabs">

    <div class="tab-buttons">
        <label for="tab1" class="tab-button">Latest</label>
        <label for="tab3" class="tab-button">Tags</label>
    </div>

    <div class="tab-content" id="chronological">
        
        <p class="link-heading">2025</p>
        <ul>
            
            <li><a href="favourites">Product recommendations</a></li>
            
            <li><a href="intellectual-progress-2024">Intellectual progress in 2024</a></li>
            
            <li><a href="activation-space-interpretability">Activation space interpretability may be doomed</a></li>
            
        </ul>
        
        <p class="link-heading">2024</p>
        <ul>
            
            <li><a href="zero-to-one">Book Summary: Zero to One</a></li>
            
            <li><a href="frontier-lab">Reasons for and against working on technical AI safety at a frontier AI lab</a></li>
            
            <li><a href="caps-lock">You should remap your caps lock key</a></li>
            
            <li><a href="phd">You should consider applying to PhDs (soon!)</a></li>
            
            <li><a href="pos-sae">Understanding positional features in layer 0 SAEs</a></li>
            
            <li><a href="rmu">Unlearning via RMU is mostly shallow</a></li>
            
            <li><a href="faithfulness">Transformer circuit faithfulness metrics are not robust</a></li>
            
            <li><a href="sad">Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs</a></li>
            
        </ul>
        
    </div>

    <div class="tab-content" id="topic">
        
        <p class="link-heading">ai</p>
        <ul>
            
            <li><a href="activation-space-interpretability">Activation space interpretability may be doomed</a></li>
            
            <li><a href="frontier-lab">Reasons for and against working on technical AI safety at a frontier AI lab</a></li>
            
            <li><a href="phd">You should consider applying to PhDs (soon!)</a></li>
            
            <li><a href="pos-sae">Understanding positional features in layer 0 SAEs</a></li>
            
            <li><a href="rmu">Unlearning via RMU is mostly shallow</a></li>
            
            <li><a href="faithfulness">Transformer circuit faithfulness metrics are not robust</a></li>
            
            <li><a href="sad">Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs</a></li>
            
        </ul>
        
        <p class="link-heading">research</p>
        <ul>
            
            <li><a href="activation-space-interpretability">Activation space interpretability may be doomed</a></li>
            
            <li><a href="pos-sae">Understanding positional features in layer 0 SAEs</a></li>
            
            <li><a href="rmu">Unlearning via RMU is mostly shallow</a></li>
            
            <li><a href="faithfulness">Transformer circuit faithfulness metrics are not robust</a></li>
            
            <li><a href="sad">Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs</a></li>
            
        </ul>
        
        <p class="link-heading">interpretability</p>
        <ul>
            
            <li><a href="activation-space-interpretability">Activation space interpretability may be doomed</a></li>
            
            <li><a href="pos-sae">Understanding positional features in layer 0 SAEs</a></li>
            
            <li><a href="rmu">Unlearning via RMU is mostly shallow</a></li>
            
            <li><a href="faithfulness">Transformer circuit faithfulness metrics are not robust</a></li>
            
        </ul>
        
        <p class="link-heading">careers</p>
        <ul>
            
            <li><a href="frontier-lab">Reasons for and against working on technical AI safety at a frontier AI lab</a></li>
            
            <li><a href="phd">You should consider applying to PhDs (soon!)</a></li>
            
        </ul>
        
        <p class="link-heading">productivity</p>
        <ul>
            
            <li><a href="favourites">Product recommendations</a></li>
            
            <li><a href="caps-lock">You should remap your caps lock key</a></li>
            
        </ul>
        
        <p class="link-heading">personal</p>
        <ul>
            
            <li><a href="intellectual-progress-2024">Intellectual progress in 2024</a></li>
            
        </ul>
        
        <p class="link-heading">books</p>
        <ul>
            
            <li><a href="zero-to-one">Book Summary: Zero to One</a></li>
            
        </ul>
        
        <p class="link-heading">startups</p>
        <ul>
            
            <li><a href="zero-to-one">Book Summary: Zero to One</a></li>
            
        </ul>
        
    </div>
</div>


            </div>
        </div>
        <!--<div class="column right">
            <div class="sticky-div">
                
            </div>
        </div>-->
    </div>
    <footer></footer>
</body>
</html>