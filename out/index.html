<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="AI. Safety. Interpretability. Rationality. Effective Altruism. Whatever else interests me.">
    <link rel="apple-touch-icon" sizes="180x180" href="/favicons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicons/favicon-16x16.png">

    <title>Bilal Chughtai </title>
    
    <link rel="stylesheet" href="css/style.css">
</head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NN7RTLBRKY"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-NN7RTLBRKY');
</script>

<body>
    
<header>
    <nav>
        <div class="site-name heading-font">Bilal Chughtai &mdash; home page</div>
    </nav>
</header>

    <div class="container">
        <div class="column left">
            <div class="sticky-div">
                
            </div>
        </div>
        <div class="column main">
            <div class="collapsed-sidebar">
                
            </div>
            <div class="content">
                
<h1 class="post-title">Bilal Chughtai</h1>

<h2 id="section-1">About</h2>

<p>I spend most of my time thinking about how to make powerful AI go well for humanity. Concretely, I work on language model
    interpretability and AGI safety at <a href="https://deepmind.google/">Google DeepMind</a>.</p>

<p>I also have a long tail of other interests, some of which I write about on this blog.</p>

<p>This site serves as a minimal home for artefacts I produce on the internet.</p>

<h2 id="section-2">Links</h2>

<p>
    <a href="https://scholar.google.com/citations?user=i-L98bwAAAAJ&hl=en">google scholar</a> //
    <a href="https://github.com/bilal-chughtai">github</a> //
    <a href="https://www.linkedin.com/in/bilalchughtai/">linkedin</a> //
    <a href="https://www.lesswrong.com/users/bilalchughtai">lesswrong</a> //
    <a href="https://x.com/bilalchughtai_">twitter</a> //
    <a href="https://www.instapaper.com/p/bilalchughtai">instapaper</a> //
    <a href="https://www.strava.com/athletes/32291390">strava</a> //
    <a href="mailto:brchughtaii@gmail.com">email</a>
</p>



<h2 id="section-2">Posts</h2>
<div class="tab-container">
    <input type="radio" id="tab1" name="tabs" checked>
    <input type="radio" id="tab2" name="tabs">
    <input type="radio" id="tab3" name="tabs">

    <div class="tab-buttons">
        <label for="tab1" class="tab-button">Latest</label>
        <label for="tab3" class="tab-button">Tags</label>
    </div>

    <div class="tab-content" id="chronological">
        
        <p class="link-heading">2025</p>
        <ul>
            
            <li><a href="coaching">Coaching is good, actually</a></li>
            
            <li><a href="efficient">Should you spend time making things more efficient?</a></li>
            
            <li><a href="products">Product recommendations</a></li>
            
            <li><a href="todo">An opinionated guide to building a good to-do system</a></li>
            
            <li><a href="e2p">everything2prompt</a></li>
            
            <li><a href="hd">My health dashboard</a></li>
            
            <li><a href="bookshelf">Bookshelf</a></li>
            
            <li><a href="gdm">Joining Google DeepMind</a></li>
            
            <li><a href="dd">Detecting strategic deception using linear probes</a></li>
            
            <li><a href="review">Open problems in mechanistic interpretability</a></li>
            
            <li><a href="intellectual-progress-2024">Intellectual progress in 2024</a></li>
            
            <li><a href="activation-space-interpretability">Activation space interpretability may be doomed</a></li>
            
        </ul>
        
        <p class="link-heading">2024</p>
        <ul>
            
            <li><a href="zero-to-one">Book Summary: Zero to One</a></li>
            
            <li><a href="frontier-lab">Reasons for and against working on technical AI safety at a frontier AI lab</a></li>
            
            <li><a href="caps-lock">You should remap your caps lock key</a></li>
            
            <li><a href="phd">You should consider applying to PhDs (soon!)</a></li>
            
            <li><a href="pos-sae">Understanding positional features in layer 0 SAEs</a></li>
            
            <li><a href="rmu">Unlearning via RMU is mostly shallow</a></li>
            
            <li><a href="faithfulness">Transformer circuit faithfulness metrics are not robust</a></li>
            
            <li><a href="sad">Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs</a></li>
            
        </ul>
        
        <p class="link-heading">2023</p>
        <ul>
            
            <li><a href="cuplc">CUPLC website enhancements</a></li>
            
        </ul>
        
        <p class="link-heading">2021</p>
        <ul>
            
            <li><a href="essay">Part III Essay: The search for CMB B-mode polarization from inflationary gravitational waves</a></li>
            
        </ul>
        
    </div>

    <div class="tab-content" id="topic">
        
        <p class="link-heading">ai</p>
        <ul>
            
            <li><a href="e2p">everything2prompt</a></li>
            
            <li><a href="gdm">Joining Google DeepMind</a></li>
            
            <li><a href="dd">Detecting strategic deception using linear probes</a></li>
            
            <li><a href="review">Open problems in mechanistic interpretability</a></li>
            
            <li><a href="activation-space-interpretability">Activation space interpretability may be doomed</a></li>
            
            <li><a href="frontier-lab">Reasons for and against working on technical AI safety at a frontier AI lab</a></li>
            
            <li><a href="phd">You should consider applying to PhDs (soon!)</a></li>
            
            <li><a href="pos-sae">Understanding positional features in layer 0 SAEs</a></li>
            
            <li><a href="rmu">Unlearning via RMU is mostly shallow</a></li>
            
            <li><a href="faithfulness">Transformer circuit faithfulness metrics are not robust</a></li>
            
            <li><a href="sad">Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs</a></li>
            
        </ul>
        
        <p class="link-heading">interpretability</p>
        <ul>
            
            <li><a href="gdm">Joining Google DeepMind</a></li>
            
            <li><a href="dd">Detecting strategic deception using linear probes</a></li>
            
            <li><a href="review">Open problems in mechanistic interpretability</a></li>
            
            <li><a href="activation-space-interpretability">Activation space interpretability may be doomed</a></li>
            
            <li><a href="pos-sae">Understanding positional features in layer 0 SAEs</a></li>
            
            <li><a href="rmu">Unlearning via RMU is mostly shallow</a></li>
            
            <li><a href="faithfulness">Transformer circuit faithfulness metrics are not robust</a></li>
            
        </ul>
        
        <p class="link-heading">productivity</p>
        <ul>
            
            <li><a href="coaching">Coaching is good, actually</a></li>
            
            <li><a href="efficient">Should you spend time making things more efficient?</a></li>
            
            <li><a href="products">Product recommendations</a></li>
            
            <li><a href="todo">An opinionated guide to building a good to-do system</a></li>
            
            <li><a href="e2p">everything2prompt</a></li>
            
            <li><a href="caps-lock">You should remap your caps lock key</a></li>
            
        </ul>
        
        <p class="link-heading">research</p>
        <ul>
            
            <li><a href="activation-space-interpretability">Activation space interpretability may be doomed</a></li>
            
            <li><a href="pos-sae">Understanding positional features in layer 0 SAEs</a></li>
            
            <li><a href="rmu">Unlearning via RMU is mostly shallow</a></li>
            
            <li><a href="faithfulness">Transformer circuit faithfulness metrics are not robust</a></li>
            
            <li><a href="sad">Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs</a></li>
            
        </ul>
        
        <p class="link-heading">paper</p>
        <ul>
            
            <li><a href="dd">Detecting strategic deception using linear probes</a></li>
            
            <li><a href="review">Open problems in mechanistic interpretability</a></li>
            
            <li><a href="faithfulness">Transformer circuit faithfulness metrics are not robust</a></li>
            
            <li><a href="sad">Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs</a></li>
            
        </ul>
        
        <p class="link-heading">careers</p>
        <ul>
            
            <li><a href="gdm">Joining Google DeepMind</a></li>
            
            <li><a href="frontier-lab">Reasons for and against working on technical AI safety at a frontier AI lab</a></li>
            
            <li><a href="phd">You should consider applying to PhDs (soon!)</a></li>
            
        </ul>
        
        <p class="link-heading">books</p>
        <ul>
            
            <li><a href="bookshelf">Bookshelf</a></li>
            
            <li><a href="zero-to-one">Book Summary: Zero to One</a></li>
            
        </ul>
        
        <p class="link-heading">startups</p>
        <ul>
            
            <li><a href="zero-to-one">Book Summary: Zero to One</a></li>
            
        </ul>
        
        <p class="link-heading">health</p>
        <ul>
            
            <li><a href="hd">My health dashboard</a></li>
            
        </ul>
        
        <p class="link-heading">physics</p>
        <ul>
            
            <li><a href="essay">Part III Essay: The search for CMB B-mode polarization from inflationary gravitational waves</a></li>
            
        </ul>
        
        <p class="link-heading">personal</p>
        <ul>
            
            <li><a href="intellectual-progress-2024">Intellectual progress in 2024</a></li>
            
        </ul>
        
        <p class="link-heading">sport</p>
        <ul>
            
            <li><a href="cuplc">CUPLC website enhancements</a></li>
            
        </ul>
        
    </div>
</div>


            </div>
        </div>
        <!--<div class="column right">
            <div class="sticky-div">
                
            </div>
        </div>-->
    </div>
    <footer></footer>

    <!-- Footnote tooltip script -->
    <script>
        document.addEventListener('DOMContentLoaded', function () {
            // Create a single tooltip element
            const tooltip = document.createElement('div');
            tooltip.className = 'footnote-tooltip';
            document.body.appendChild(tooltip);
            let hideTimer;

            function positionTooltip(ref) {
                const rect = ref.getBoundingClientRect();
                const scrollX = window.scrollX || window.pageXOffset;
                const scrollY = window.scrollY || window.pageYOffset;
                // Initial placement below the reference
                let top = scrollY + rect.bottom + 8;
                let left = scrollX + rect.left;
                tooltip.style.top = top + 'px';
                tooltip.style.left = left + 'px';
                // Adjust if it overflows the right edge
                const tt = tooltip.getBoundingClientRect();
                const viewportWidth = document.documentElement.clientWidth;
                if (tt.right > viewportWidth - 8) {
                    const overflow = tt.right - (viewportWidth - 8);
                    tooltip.style.left = (left - overflow) + 'px';
                }
                // Adjust if it overflows the left edge
                if (tt.left < 8) {
                    tooltip.style.left = (scrollX + 8) + 'px';
                }
            }

            function showTooltip(ref) {
                clearTimeout(hideTimer);
                tooltip.innerHTML = ref.getAttribute('data-footnote');
                tooltip.style.display = 'block';
                positionTooltip(ref);
            }

            function hideTooltip() {
                hideTimer = setTimeout(() => {
                    tooltip.style.display = 'none';
                }, 300); // 300ms delay before hiding
            }

            // Attach events to each footnote reference
            document.querySelectorAll('a.footnote-ref').forEach(function (ref) {
                ref.addEventListener('mouseenter', () => showTooltip(ref));
                ref.addEventListener('mouseleave', hideTooltip);
            });

            // Keep tooltip open when hovering over it
            tooltip.addEventListener('mouseenter', () => clearTimeout(hideTimer));
            tooltip.addEventListener('mouseleave', hideTooltip);
        });
    </script>
</body>

</html>